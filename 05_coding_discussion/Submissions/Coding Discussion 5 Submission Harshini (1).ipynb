{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Coding Discussion 5 _ Harshini \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Can we predict whether someone will vote or not?\n",
    "\n",
    "In the discussion folder, you'll find the turnout.csv data, which was drawn from the 2012 National Election Survey. The data records the age, eduction level (of total years in school), income, race (caucasian or not), and past voting record (i.e. whether or not the respondent voted in the 2012 Presidential election). The sample is composed of 2000 individual respondents.\n",
    "\n",
    "Please break the data up into a training (1600 entries, 80%) and test dataset (400 entries, 20%).\n",
    "\n",
    "Build a Naive Bayesian Classifier from scratch that tries to predict whether a respondent will vote in a presidential election or not, pr(Vote==1). The classifier must be built from scratch. Do not use a third party ML or statistical package.\n",
    "\n",
    "Run your algorithm and see how it predicts on the test data. Use the sklearn.metrics library to calculate the predictive accuracy and the area underneath the ROC curve.\n",
    "\n",
    "Does your model perform better than chance (i.e. coin flip)?\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "- As asked, in this file, a Naive Bayesian classifier was built from scratch. It takes one input file, i.e., turnout. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Importing required packages\n",
    "import pandas as pd \n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt #for plotting\n",
    "from random import shuffle #for shuffling the data before splitting it\n",
    "from sklearn.naive_bayes import GaussianNB # Classifier \n",
    "import sklearn.metrics as m # sklearn.metrics to determine the classification "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### Reading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        id  age  educate  income  vote  white\n",
      "0        1   60     14.0  3.3458     1      1\n",
      "1        2   51     10.0  1.8561     0      1\n",
      "2        3   24     12.0  0.6304     0      1\n",
      "3        4   38      8.0  3.4183     1      1\n",
      "4        5   25     12.0  2.7852     1      1\n",
      "...    ...  ...      ...     ...   ...    ...\n",
      "1995  1996   26     16.0  3.3834     0      1\n",
      "1996  1997   34     12.0  2.9170     1      1\n",
      "1997  1998   51     16.0  7.8949     1      1\n",
      "1998  1999   22     10.0  2.4811     0      1\n",
      "1999  2000   59     10.0  0.5523     0      1\n",
      "\n",
      "[2000 rows x 6 columns]\n"
     ]
    }
   ],
   "source": [
    "##Loading data\n",
    "turnout = pd.read_csv(\"C:/Users/VIOLIN/Desktop/Coding discussion 5/turnout.csv\")\n",
    "##Printing data\n",
    "print(turnout)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        id  age  educate   income  vote  white\n",
      "998    999   27     14.0   8.7545     1      1\n",
      "1779  1780   63      4.0   2.2092     0      1\n",
      "650    651   24     12.0   1.4055     0      1\n",
      "1987  1988   62      9.0   0.7294     0      0\n",
      "1757  1758   49     14.0  11.2307     1      1\n",
      "...    ...  ...      ...      ...   ...    ...\n",
      "1322  1323   45     15.0   9.1907     1      1\n",
      "909    910   42     12.0   8.7220     1      1\n",
      "1432  1433   52      9.0   3.7042     1      1\n",
      "330    331   62      6.0   2.9170     1      1\n",
      "1772  1773   23     16.0   0.2364     1      1\n",
      "\n",
      "[2000 rows x 6 columns]\n"
     ]
    }
   ],
   "source": [
    "# Shuffling the data\n",
    "\n",
    "turnout_r = turnout.sample(frac=1)\n",
    "#Printing the shuffled data\n",
    "print(turnout_r)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Breaking the data into testing and training dataset\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        id  age  educate   income  vote  white\n",
      "998    999   27     14.0   8.7545     1      1\n",
      "1779  1780   63      4.0   2.2092     0      1\n",
      "650    651   24     12.0   1.4055     0      1\n",
      "1987  1988   62      9.0   0.7294     0      0\n",
      "1757  1758   49     14.0  11.2307     1      1\n",
      "...    ...  ...      ...      ...   ...    ...\n",
      "148    149   38      5.0   1.4498     1      1\n",
      "1117  1118   39     14.0   7.5945     1      1\n",
      "172    173   27     12.0   1.8429     1      1\n",
      "25      26   39     16.0  10.0376     1      1\n",
      "548    549   46      7.0   0.5523     1      0\n",
      "\n",
      "[400 rows x 6 columns]\n",
      "        id  age  educate  income  vote  white\n",
      "1186  1187   28     12.0  2.9170     1      1\n",
      "391    392   52     14.0  4.4876     1      1\n",
      "1620  1621   36     12.0  4.0702     1      1\n",
      "1763  1764   57     16.0  3.8606     0      1\n",
      "1478  1479   66     14.0  0.7953     1      1\n",
      "...    ...  ...      ...     ...   ...    ...\n",
      "1322  1323   45     15.0  9.1907     1      1\n",
      "909    910   42     12.0  8.7220     1      1\n",
      "1432  1433   52      9.0  3.7042     1      1\n",
      "330    331   62      6.0  2.9170     1      1\n",
      "1772  1773   23     16.0  0.2364     1      1\n",
      "\n",
      "[1600 rows x 6 columns]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#Splitting the data into testing and training data\n",
    "testing_dataset = turnout_r[0:400]\n",
    "training_dataset = turnout_r[400:2000]\n",
    "#Printing outputs to cross check \n",
    "print(testing_dataset)\n",
    "print(training_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " #### Naive Bayesian Classifier "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### THEORY OF THE CLASSIFIER\n",
    "\n",
    "#### - Bayes Theorem : P(A/B) = [P(B/A) * P(A)] / P(B)\n",
    "#### - Applying the theorem to the current problem : P(y/X) = P(X/y) * P(y)/P(X)\n",
    "##### Explaining the terms : X - feature vector i.e., X = {x1,x2,x3,x4,x5}x1-age ,x2-educate,x3-income,x4-white; y-vote ; \n",
    "##### P(y/X) - Posterior Probability;P(x1/y),P(x2/y),P(x3/y),P(x4/y),P(x5/y)- Class Conditional Probabilities; P(X);P(y) - Prior Probabilities;Prior - Frequency\n",
    "#### As we are creating a Naive Bayesian Classifier, all the features(x1-x5) are considered to be mutually independent : P(X/y) = P(x1/y).P(x2/y).P(x3/y).P(x4/y).P(x5/y)\n",
    "\n",
    "#### Calculating Class Conditional Probability : P(xi/y) =  (1/(2*pi*sigma_y^2))*exp(-(xi-mu_y)^2/(2*sigma_y^2);sigma - variance; mu - mean value\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#creating a class NaiveBayes with necessary NB classifier functions loaded\n",
    "class NaiveBayes:\n",
    "    \"\"\"\n",
    "    The defined class NaiveBayes contains four functions defined,i.e., fit to calculate mean,variance and prior, predict to \n",
    "    calculate overall required prediction value ,_predict to calculate prediction value with one feature variable and \n",
    "    _pdf to help predict function\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    def fit(self,X,y): \n",
    "        \n",
    "        n_rows,n_columns= X.shape #Since X is an array with rows and columns\n",
    "        self._classes = np.unique(y) # to find the unique elements of the array\n",
    "        n_classes =len(self._classes)\n",
    "        #init mean, variance and prior\n",
    "        self._mean = np.zeros((n_classes,n_columns),dtype =np.float64)\n",
    "        self._var = np.zeros((n_classes,n_columns),dtype =np.float64)\n",
    "        self._prior =np.zeros((n_classes),dtype =np.float64)\n",
    "        \n",
    "        for c in self._classes: #For class in self._classes\n",
    "            X_c = X[c==y]\n",
    "            self._mean[c,:] = X_c.mean(axis=0) # to calculate mean for each class\n",
    "            self._var[c,:] = X_c.var(axis=0) # to calculate variance for each class\n",
    "            self._prior[c] = X_c.shape[0]/float(n_rows) #frequency\n",
    "            \n",
    "    def predict(self,X):\n",
    "        \n",
    "        y_predict = [self._predict(x) for x in X] \n",
    "        return y_predict  # return output    \n",
    "    \n",
    "    def _predict(self,x):\n",
    "       \n",
    "        posterior = [] # Create an empty list \n",
    "        for idx, c in enumerate(self._classes):#idx -> index \n",
    "            prior = np.log(self._prior[idx]) #prior probability as log(for%)\n",
    "            # calculating class cond prob using a _pdf function,defined below\n",
    "            class_cond_prob = np.sum(np.log(self._pdf(idx,x))) \n",
    "            posterior1 =  class_cond_prob + prior #Summing class conditional prob's and prior prob\n",
    "            posterior.append(posterior1) #Final Posterior Probability\n",
    "            return self._classes[np.argmax(posterior)] #index with highest prob\n",
    "        \n",
    "\n",
    "            \n",
    "    def _pdf(self, class_index, x):\n",
    "        mean = self._mean[class_index]#calculating mu i.e., mean\n",
    "        var = self._var[class_index] #calculating sigma,i.e., variance\n",
    "        numerator = np.exp(- (x-mean)**2 / (2 * var))#numerator for class conditional prob\n",
    "        denominator = np.sqrt(2* np.pi * var)#denominator for class conditional prob\n",
    "        return numerator / denominator #output for calculating class conditional prob\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Accuracy of the created NB Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(y_true, y_predict): \n",
    "    \"\"\"\n",
    "    The defined accuracy function helps us find out the accuracy of the created NB Classifier\n",
    "    \"\"\"\n",
    "    accuracy = np.sum(y_true == y_predict) / len(y_true) # defining accuracy\n",
    "    return accuracy #return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2625\n",
      "0.251875\n"
     ]
    }
   ],
   "source": [
    "nb = NaiveBayes() ##Calling the created class\n",
    "\n",
    "y_train = training_dataset[\"vote\"] #creating y(vote) dataset for training dataset\n",
    "X_train = training_dataset.drop(columns=[\"vote\"])#creating X feature vector dataset for training dataset\n",
    "X_train= X_train.reset_index().values#to reset the index of dataset\n",
    "y_test = testing_dataset[\"vote\"]#creating y(vote) dataset for testing dataset\n",
    "X_test = testing_dataset.drop(columns=[\"vote\"])#creating X feature vector  dataset for  testing dataset\n",
    "X_test= X_test.reset_index().values#to reset the index of dataset\n",
    "nb.fit(X_train,y_train) #Calling the classifier for training data\n",
    "prediction = nb.predict(X_test) #Prediction for testing data\n",
    "prediction1 = nb.predict(X_train)#Prediction for trainining data\n",
    "\n",
    "print(accuracy(y_test, prediction)) #Output #accuracy is too low for the testing data\n",
    "print(accuracy(y_train, prediction1))#Output #accuracy is too low for the trainig data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Comparing the accuracy with Sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.735"
      ]
     },
     "execution_count": 268,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Accuracy calculation with Sklearn metrics\n",
    "# Instantiate the model class \n",
    "gnb = GaussianNB()\n",
    "gnb.fit(X_train, y_train)\n",
    "\n",
    "# Prediction value\n",
    "y_pred = gnb.predict(X_test)\n",
    "\n",
    "# Accuracy with Sklearn\n",
    "m.accuracy_score(y_test,y_pred) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ROC Curve "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5811138014527846"
      ]
     },
     "execution_count": 269,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "#Area under the ROC curve\n",
    "m.roc_auc_score(y_test,y_pred) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Discussion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- AUC of the classifier is 0.598 while coin flip has 0.5 chance. So, the model performs 18% better than the coin flip.  \n",
    "- Accuracy for the defined classifier is very low .Improving the method of sampling might address the issue. \n",
    "    \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
