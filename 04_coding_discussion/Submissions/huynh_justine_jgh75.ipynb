{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparing Similarities Among News Outlets Of The Khashoggi Murder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing Important Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading The Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading the files\n",
    "# Use the ../ to indicate that computer has to search for Data folder\n",
    "alj = open(\"../Data/aljazeera-khashoggi.txt\", 'r', encoding = \"UTF-8\").read()\n",
    "bbc = open(\"../Data/bbc-khashoggi.txt\", \"r\", encoding = \"UTF-8\").read()\n",
    "breit = open(\"../Data/breitbart-khashoggi.txt\", \"r\", encoding = \"UTF-8\").read()\n",
    "cnn = open(\"../Data/cnn-khashoggi.txt\", \"r\", encoding = \"UTF-8\").read()\n",
    "fox = open(\"../Data/fox-khashoggi.txt\", \"r\", encoding = \"UTF-8\").read()\n",
    "stopWords = pd.read_csv(\"../Data/stop_words.csv\", encoding = \"UTF-8\")\n",
    "stopWordsList = stopWords[\"word\"].values\n",
    "\n",
    "# If you wanted to use a smaller set of stopwords\n",
    "# Words common to the English Language\n",
    "#stopWords = ['on', 'to', 'go', 'at', 'the','that','of','was', 'and', 'by']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Necessary Functions/Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(text=None):\n",
    "    '''\n",
    "    Tokenizes a text\n",
    "    @param text the specified text\n",
    "    @return a list of words from the text\n",
    "    '''\n",
    "    text = text.lower()\n",
    "    \n",
    "    # Eradicate all the non-characters\n",
    "    text = text.replace('.','')\n",
    "    text = text.replace(\"(\", \"\")\n",
    "    text = text.replace(\")\", \"\")\n",
    "    text = text.replace(\"-\", \"\")\n",
    "    text = text.replace(\"[\", \"\")\n",
    "    text = text.replace(\"]\", \"\")\n",
    "    \n",
    "    # Eradicate punctuation marks too...\n",
    "    text = text.replace(\"?\", \"\")\n",
    "    text = text.replace(\",\", \"\")\n",
    "    text = text.replace(\"!\", \"\")\n",
    "    text = text.replace(\"\\\"\", \"\")\n",
    "    text = text.replace(\"’s\", \"\")\n",
    "    text = text.replace(\"’\", \"\")\n",
    "    text = text.replace(\"\\'\", \"\")\n",
    "    text = text.replace(\"{\", \"\")\n",
    "    text = text.replace(\"}\", \"\")\n",
    "    text = text.replace(\"\\n\", \"\")\n",
    "    text = text.replace(\"“\", \"\")\n",
    "    text = text.replace(\"”\", \"\")\n",
    "    text = text.replace(\"—\", \"\")\n",
    "    text = text.replace(\";\", \"\")\n",
    "    \n",
    "    return text\n",
    "#     #Then split by spaces\n",
    "#     text_list = text.split()\n",
    "#     text_list2 = [word for word in text_list if word not in stopWordsList]\n",
    "#     return text_list2\n",
    "\n",
    "\n",
    "def tokenizeToList(text):\n",
    "    '''\n",
    "    Tokenizes the text into a list\n",
    "    @param text the cleaned, parsed text\n",
    "    @return the list of tokenized, cleaned, parsed words\n",
    "    '''    \n",
    "    #Then split by spaces\n",
    "    text_list = text.split()\n",
    "    text_list2 = [word for word in text_list if word not in stopWordsList]\n",
    "    return text_list2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize the words, but don't convert them to lists yet\n",
    "aljWords = tokenize(alj)\n",
    "bbcWords = tokenize(bbc)\n",
    "breitWords = tokenize(breit)\n",
    "cnnWords = tokenize(cnn)\n",
    "foxWords = tokenize(fox)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now have a bunch of words from each text file. Let's now convert these texts into a document term matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def toDictionary(txt):\n",
    "    '''\n",
    "    Converts text into a document term matrix.\n",
    "    @param txt the text\n",
    "    @return the document term matrix, to be used in a dataframe\n",
    "    '''    \n",
    "    # Spawn a dictionary\n",
    "    d = dict()\n",
    "    \n",
    "    # Tokenize (toList) the text\n",
    "    #for word in tokenize(txt):\n",
    "    for word in tokenizeToList(txt):\n",
    "        \n",
    "        # if the word is in the dictionary, give it a 1\n",
    "        if word in d:\n",
    "            d[word][0] += 1\n",
    "        \n",
    "        # Otherwise, give it a value of 1. First time encountering this word\n",
    "        else:\n",
    "            d[word] = [1]\n",
    "    return pd.DataFrame(d)\n",
    "\n",
    "\n",
    "def toDTM(texts = None):\n",
    "    '''\n",
    "        Converts a list of texts into a document term matrix\n",
    "        @param texts a list of words\n",
    "        @return the document term matrix\n",
    "    '''    \n",
    "    # Spawn a data frame\n",
    "    DTM = pd.DataFrame()\n",
    "    \n",
    "    # For every word in the list of words\n",
    "    for text in texts:\n",
    "        # convert to a dictionary\n",
    "        entry = toDictionary(text)\n",
    "        # Append to the data frame document term matrix\n",
    "        DTM = DTM.append(pd.DataFrame(entry), ignore_index = True, sort=True) # Row bind\n",
    "    \n",
    "    DTM.fillna(0, inplace=True) # Fill in any missing values with 0s (i.e. when a word is in one text but not another)\n",
    "    return DTM\n",
    "\n",
    "# Name things the Java way, like a BOSS!\n",
    "DTM = toDTM([aljWords, bbcWords, breitWords, cnnWords, foxWords])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let us find some disimilarities and similarities among the 5 different news reporter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def cosine(a,b):\n",
    "    '''\n",
    "    Calculates how related (or unrelated) to vectors are\n",
    "    by calculating the cosine of the angle between them\n",
    "    @param a a matrix/vector/column\n",
    "    @param b another matrix/vector/column\n",
    "    @return the cosine of the angle between the 2 vectors\n",
    "    '''\n",
    "    cos = np.dot(a,b)/(np.sqrt(np.dot(a,a)) * np.sqrt(np.dot(b,b))  )\n",
    "    return round(cos, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparing The Different Newspaper Reports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i =  Aljazaar , j =  BBC , and cosine: 0.679\n",
      "i =  Aljazaar , j =  Breitbart , and cosine: 0.588\n",
      "i =  Aljazaar , j =  CNN , and cosine: 0.533\n",
      "i =  Aljazaar , j =  Fox , and cosine: 0.681\n",
      "i =  BBC , j =  Breitbart , and cosine: 0.606\n",
      "i =  BBC , j =  CNN , and cosine: 0.504\n",
      "i =  BBC , j =  Fox , and cosine: 0.653\n",
      "i =  Breitbart , j =  CNN , and cosine: 0.404\n",
      "i =  Breitbart , j =  Fox , and cosine: 0.576\n",
      "i =  CNN , j =  Fox , and cosine: 0.547\n"
     ]
    }
   ],
   "source": [
    "# Let's loop through all the different rows\n",
    "# Or, through all the 5 different news reporter\n",
    "reporterList = [\"Aljazaar\", \"BBC\", \"Breitbart\", \"CNN\", \"Fox\"]\n",
    "for i in range(5):\n",
    "    for j in range(i + 1, 5):\n",
    "        \n",
    "        print(\"i = \", reporterList[i], \", j = \", reporterList[j], \", and cosine:\", round(cosine(DTM.iloc[i,:], DTM.iloc[j, :]), 3))\n",
    "        #counter = counter + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create something like a correlation matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Aljazaar</th>\n",
       "      <th>BBC</th>\n",
       "      <th>Breitbart</th>\n",
       "      <th>CNN</th>\n",
       "      <th>Fox</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Aljazaar</th>\n",
       "      <td>1.000</td>\n",
       "      <td>0.679</td>\n",
       "      <td>0.588</td>\n",
       "      <td>0.533</td>\n",
       "      <td>0.681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BBC</th>\n",
       "      <td>0.679</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.606</td>\n",
       "      <td>0.504</td>\n",
       "      <td>0.653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Breitbart</th>\n",
       "      <td>0.588</td>\n",
       "      <td>0.606</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.404</td>\n",
       "      <td>0.576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CNN</th>\n",
       "      <td>0.533</td>\n",
       "      <td>0.504</td>\n",
       "      <td>0.404</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fox</th>\n",
       "      <td>0.681</td>\n",
       "      <td>0.653</td>\n",
       "      <td>0.576</td>\n",
       "      <td>0.547</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Aljazaar    BBC  Breitbart    CNN    Fox\n",
       "Aljazaar      1.000  0.679      0.588  0.533  0.681\n",
       "BBC           0.679  1.000      0.606  0.504  0.653\n",
       "Breitbart     0.588  0.606      1.000  0.404  0.576\n",
       "CNN           0.533  0.504      0.404  1.000  0.547\n",
       "Fox           0.681  0.653      0.576  0.547  1.000"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "def toCorrelationMatrix(df):\n",
    "    '''\n",
    "    Transforms a dataframe into a correlation matrix (in the form of dataframe)\n",
    "    @param df the dataframe\n",
    "    @return the new simulated correlated matrix (in the form of dataframe)\n",
    "    '''\n",
    "    reporterList = [\"Aljazaar\", \"BBC\", \"Breitbart\", \"CNN\", \"Fox\"]\n",
    "    # Spawn an empty data frame as a correlation matrix\n",
    "    correlationFrame = pd.DataFrame() \n",
    "    for i in range(len(reporterList)):\n",
    "        column = []\n",
    "        for j in range(len(reporterList)):\n",
    "            \n",
    "            # The cosine\n",
    "            column.append(cosine(df.iloc[i, :], df.iloc[j, :]))\n",
    "        # And when you are done with completing 1 full column of correlation matrix\n",
    "        # add it to the dataframe\n",
    "        correlationFrame[reporterList[i]] = column\n",
    "    correlationFrame = correlationFrame.rename(index = \n",
    "                    {\n",
    "                        0 : \"Aljazaar\",\n",
    "                        1 : \"BBC\",\n",
    "                        2 : \"Breitbart\",\n",
    "                        3 : \"CNN\",\n",
    "                        4 : \"Fox\"\n",
    "                   }\n",
    "                )\n",
    "    return correlationFrame\n",
    "        \n",
    "correlationMatrix = toCorrelationMatrix(DTM)\n",
    "correlationMatrix    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The max cosine (most similar) occurs between Aljazaar and Fox when discussing the Khashoggi murder (cosine = 0.679). BBC comes to a close second in terms of being similar with Aljazaar. So not surprisingly, BBC and Fox are quite similar to each other when compared to other news outlets. The minimum cosine (most dissimilar) occured between Breitbart and CNN (cosine = 0.404).\n",
    "\n",
    "If we had used a smaller set of `stopWords`, then the similarities among all the newspaper reports will increase."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
