{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CODING DISCUSSION 4 \n",
    "\n",
    "### Submitted by HARSHINI(ht442)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'install' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-263-6eaca7d54306>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Importing packages\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0minstall\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpackages\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"ggcorrplot\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'install' is not defined"
     ]
    }
   ],
   "source": [
    "# Importing packages\n",
    "install.packages(\"ggcorrplot\")\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading the given five newspaper text files into 'alz','bbc','bbt','cnn' and 'fox' variables \n",
    "str1 = open(\"C:/Users/VIOLIN/Data/aljazeera-khashoggi.txt\", \"r\",encoding = \"UTF-8\")\n",
    "str2= open(\"C:/Users/VIOLIN/Data/bbc-khashoggi.txt\", \"r\",encoding = \"UTF-8\")\n",
    "str3 = open(\"C:/Users/VIOLIN/Data/breitbart-khashoggi.txt\", \"r\",encoding = \"UTF-8\")\n",
    "str4 = open(\"C:/Users/VIOLIN/Data/cnn-khashoggi.txt\", \"r\",encoding = \"UTF-8\")\n",
    "str5 = open(\"C:/Users/VIOLIN/Data/fox-khashoggi.txt\", \"r\",encoding = \"UTF-8\")\n",
    "swds = pd.read_csv(\"C:/Users/VIOLIN/Data/stop_words.csv\")\n",
    "\n",
    "# reading the data from the loaded txt files\n",
    "alz = str1.read()\n",
    "bbc = str2.read()\n",
    "bbt = str3.read()\n",
    "cnn = str4.read()\n",
    "fox = str5.read()\n",
    "\n",
    "# Creating list of Words from the stop words csv file \n",
    "\n",
    "swds_list = swds[\"word\"].values "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Filtering  the newspaper articles for required words\n",
    "#### Defining tokenize function to break the strings into bucket of words. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(text=None):\n",
    "    \"\"\"\n",
    "    The defined Tokenize function removes punctuations marks and any other non letter details of the string, stopwords(from the csv file) and returns \n",
    "    string as a uniform list of words in lower case \n",
    "    \n",
    "    \"\"\"\n",
    "    #Converting the text into Lower case\n",
    "    text = text.lower()\n",
    "    #Replacing punctuation marks and other non letter details from the string with single quotes\n",
    "    text = text.replace('.','')\n",
    "    text = text.replace(',','')\n",
    "    text = text.replace('(','')\n",
    "    text = text.replace(')','')\n",
    "    text = text.replace('\"','')\n",
    "    text = text.replace('-','')\n",
    "    text = text.replace('_','')\n",
    "    text = text.replace(\"“\", \"\")\n",
    "    text = text.replace(\"”\", \"\")\n",
    "    text = text.replace('[','')\n",
    "    text = text.replace(']','')\n",
    "    text = text.replace(\"\\'s\",'')\n",
    "    text = text.replace(\"?\",'')\n",
    "    text = text.replace(\"\\'\",'')\n",
    "    text = text.replace('{','')\n",
    "    text = text.replace('}','')\n",
    "\n",
    "    #Splitting the string into blocks of words\n",
    "\n",
    "    list1 = text.split()\n",
    "    # Removing stop words from the function output\n",
    "    list2 = [i for i in list1 if i not in swds_list]\n",
    "\n",
    "    return list2\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['turkey', 'istanbul', 'turkish', 'president', 'recep', 'tayyip', 'erdogan', 'murder', 'journalist', 'jamal', 'khashoggi', 'kingdom', 'consulate', 'istanbul', 'planned', 'saudi', 'officials', 'days', 'advance', 'addressing', 'legislators', 'justice', 'development', 'party', 'ak', 'party', 'tuesday', 'erdogan', 'detailed', 'khashoggi', 'disappearance', 'murder', 'stopped', 'short', 'accusing', 'saudi', 'royals', 'savage', 'killing', 'caused', 'global', 'outrage', 'september', '28', 'khashoggi', 'arrived', 'saudi', 'arabian', 'consulate', 'sort', 'wedding', 'paperwork', 'erdogan', 'speech', 'turkish', 'parliament', 'capital', 'ankara', 'time', 'saudi', 'arabian', 'officials', 'started', 'plan', 'roadmap', 'murder', 'added', 'saudi', 'officials', 'left', 'turkey', 'travelled', 'saudi', 'arabia', 'indicating', 'planned', 'murder', 'khashoggi', '59', 'washington', 'post', 'columnist', 'critic', 'powerful', 'saudi', 'crown', 'prince', 'mohammed', 'bin', 'salman', 'disappeared', 'entering', 'saudi', 'consulate', 'october', '2', 'tuesday', 'speech', 'erdogan', 'remained', 'silent', 'unnamed', 'turkish', 'officials', 'leaked', 'information', 'murder', 'including', 'information', '15member', 'saudi', 'assassination', 'team', 'flew', 'istanbul', 'chartered', 'planes', 'wake', 'intense', 'global', 'pressure', 'saudi', 'arabia', 'admitted', 'week', 'khashoggi', 'killed', 'inside', 'istanbul', 'consulate', 'october', '2', 'result', 'fistfight', 'interrogation', 'saudi', 'authorities', 'arrested', '18', 'people', 'connection', 'killing', 'fired', 'top', 'security', 'officials', 'considered', 'close', 'bin', 'salman', 'erdogan', 'called', 'killing', 'political', 'murder', 'adding', 'international', 'investigators', 'included', 'probe', 'turkish', 'leader', 'call', 'killing', 'savage', 'adding', 'ankara', 'continue', 'investigation', 'questions', 'answered', 'saudi', 'team', 'istanbul', 'instruction', 'erdogan', 'adding', 'saudi', 'arabia', 'investigators', 'consulate', 'days', 'body', 'galip', 'dalay', 'visiting', 'scholar', 'university', 'oxford', 'stressed', 'significance', 'erdogan', 'speech', 'erdogan', 'confirmed', 'sort', 'heard', 'channels', 'told', 'al', 'jazeera', 'attributed', 'unnamed', 'turkish', 'officials', 'president', 'turkey', 'confirmed', 'happened', 'dalay', 'erdogan', 'demanded', 'answers', 'happened', 'khashoggi', 'body', 'mentioning', 'reports', 'local', 'cooperator', 'allegedly', 'disposed', 'body', 'claims', 'body', 'local', 'person', 'local', 'person', 'erdogan', 'allowed', 'answering', 'questions', 'added', 'turkish', 'president', 'saudi', 'arabia', 'taking', 'steps', 'ankara', 'investigation', 'carrying', '18', 'arrests', 'dalay', 'nonresident', 'fellow', 'brookings', 'institution', 'doha', 'underlined', 'erdogan', 'distinction', 'speech', 'king', 'salman', 'son', 'bin', 'salman', 'erdogan', 'provided', 'mbs', 'naming', 'crown', 'prince', 'specifically', 'dalay', 'adding', 'turkish', 'president', 'prevent', 'fullblown', 'crisis', 'ankara', 'riyadh', 'sunday', 'speaking', 'exclusive', 'interview', 'fox', 'news', 'saudi', 'arabia', 'foreign', 'minister', 'adel', 'aljubeir', 'khashoggi', 'killing', 'inside', 'consulate', 'terrible', 'tragedy', 'mbs', 'taha', 'ozhan', 'research', 'director', 'ankara', 'institute', 'told', 'al', 'jazeera', 'erdogan', 'taking', 'steps', 'saudis', 'turkey', 'erdogan', 'saudis', 'cooperation']\n"
     ]
    }
   ],
   "source": [
    "## Applying the tokenize function to all the five strings alz,bbc,bbt,cnn and fox to break each string into its word blocks and Checking the Output\n",
    "alz_tkn = tokenize(alz)\n",
    "bbc_tkn = tokenize(bbc)\n",
    "bbt_tkn = tokenize(bbt)\n",
    "cnn_tkn = tokenize(cnn)\n",
    "fox_tkn = tokenize(fox)\n",
    "\n",
    "print(alz_tkn) # checking output\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating a Document Term Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Dict(text1=None):\n",
    "    \"\"\"\n",
    "    The defined Dict Function creates a document term matrix(frequency of each word in the document in matrix form)\n",
    "    \"\"\"\n",
    "    # Create an Empty dictionary\n",
    "    \n",
    "    di = {}\n",
    "     # Counting the frequency of words using if else statement\n",
    "    for word in tokenize(text1):\n",
    "        \n",
    "        if word in di:\n",
    "            di[word][0] += 1 #to count the frequency of existing words\n",
    "        else:\n",
    "            di[word] = [1]\n",
    "    return pd.DataFrame(di)\n",
    "            \n",
    "    #Creating the output as dataframe\n",
    "    return pd.DataFrame(di,ignore_index=True)\n",
    "\n",
    "def DTM(text2):\n",
    "    \"\"\"\n",
    "    The DTM function generates a Document Term Matrix in the form of a dataframe for all the news articles\n",
    "    \"\"\"\n",
    "    # Create a dataframe\n",
    "    DTM = pd.DataFrame()\n",
    "    \n",
    "    for text in text2:\n",
    "        entry = Dict(text)\n",
    "        #Row bind # Binding multiple dataframes\n",
    "        DTM = DTM.append(pd.DataFrame(entry),ignore_index=True,sort=True)\n",
    "    \n",
    "    DTM.fillna(0, inplace=True) #to Fill empty boxes of the dataframe with zeros to avoid confusion\n",
    "    \n",
    "    return DTM\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [],
   "source": [
    "Document_term_matrix = DTM([alz,bbc,bbt,cnn,fox])#Creating the Document term matrix for our newspaper articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>$50bn</th>\n",
       "      <th>1</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>15</th>\n",
       "      <th>15member</th>\n",
       "      <th>18</th>\n",
       "      <th>1:08</th>\n",
       "      <th>2</th>\n",
       "      <th>28</th>\n",
       "      <th>...</th>\n",
       "      <th>widely</th>\n",
       "      <th>withheld</th>\n",
       "      <th>woods</th>\n",
       "      <th>world</th>\n",
       "      <th>worse</th>\n",
       "      <th>writer</th>\n",
       "      <th>yalova</th>\n",
       "      <th>yelova</th>\n",
       "      <th>£385bn</th>\n",
       "      <th>—</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 655 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   $50bn    1   11   12   15  15member   18  1:08    2   28  ...  widely  \\\n",
       "0    0.0  0.0  0.0  0.0  0.0       1.0  2.0   0.0  2.0  1.0  ...     0.0   \n",
       "1    1.0  0.0  0.0  1.0  0.0       0.0  2.0   0.0  1.0  0.0  ...     1.0   \n",
       "2    0.0  0.0  0.0  0.0  1.0       0.0  0.0   0.0  0.0  0.0  ...     0.0   \n",
       "3    0.0  0.0  0.0  0.0  0.0       0.0  1.0   0.0  0.0  0.0  ...     0.0   \n",
       "4    0.0  1.0  1.0  0.0  1.0       0.0  1.0   1.0  1.0  0.0  ...     0.0   \n",
       "\n",
       "   withheld  woods  world  worse  writer  yalova  yelova  £385bn    —  \n",
       "0       0.0    0.0    0.0    0.0     0.0     0.0     0.0     0.0  0.0  \n",
       "1       0.0    0.0    1.0    0.0     0.0     0.0     0.0     1.0  0.0  \n",
       "2       1.0    0.0    1.0    0.0     0.0     0.0     0.0     0.0  0.0  \n",
       "3       0.0    0.0    0.0    0.0     0.0     1.0     0.0     0.0  0.0  \n",
       "4       0.0    1.0    0.0    1.0     2.0     0.0     1.0     0.0  3.0  \n",
       "\n",
       "[5 rows x 655 columns]"
      ]
     },
     "execution_count": 255,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Document_term_matrix #Viewing output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [],
   "source": [
    " Document_term_matrix = Document_term_matrix .rename(index={0:\"aljazeera\", 1:\"bbc\", 2:\"breitbart\", 3:\"cnn\", 4:\"fox\"}) # Adding index details for more readability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>$50bn</th>\n",
       "      <th>1</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>15</th>\n",
       "      <th>15member</th>\n",
       "      <th>18</th>\n",
       "      <th>1:08</th>\n",
       "      <th>2</th>\n",
       "      <th>28</th>\n",
       "      <th>...</th>\n",
       "      <th>widely</th>\n",
       "      <th>withheld</th>\n",
       "      <th>woods</th>\n",
       "      <th>world</th>\n",
       "      <th>worse</th>\n",
       "      <th>writer</th>\n",
       "      <th>yalova</th>\n",
       "      <th>yelova</th>\n",
       "      <th>£385bn</th>\n",
       "      <th>—</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>aljazeera</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bbc</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>breitbart</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cnn</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fox</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 655 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           $50bn    1   11   12   15  15member   18  1:08    2   28  ...  \\\n",
       "aljazeera    0.0  0.0  0.0  0.0  0.0       1.0  2.0   0.0  2.0  1.0  ...   \n",
       "bbc          1.0  0.0  0.0  1.0  0.0       0.0  2.0   0.0  1.0  0.0  ...   \n",
       "breitbart    0.0  0.0  0.0  0.0  1.0       0.0  0.0   0.0  0.0  0.0  ...   \n",
       "cnn          0.0  0.0  0.0  0.0  0.0       0.0  1.0   0.0  0.0  0.0  ...   \n",
       "fox          0.0  1.0  1.0  0.0  1.0       0.0  1.0   1.0  1.0  0.0  ...   \n",
       "\n",
       "           widely  withheld  woods  world  worse  writer  yalova  yelova  \\\n",
       "aljazeera     0.0       0.0    0.0    0.0    0.0     0.0     0.0     0.0   \n",
       "bbc           1.0       0.0    0.0    1.0    0.0     0.0     0.0     0.0   \n",
       "breitbart     0.0       1.0    0.0    1.0    0.0     0.0     0.0     0.0   \n",
       "cnn           0.0       0.0    0.0    0.0    0.0     0.0     1.0     0.0   \n",
       "fox           0.0       0.0    1.0    0.0    1.0     2.0     0.0     1.0   \n",
       "\n",
       "           £385bn    —  \n",
       "aljazeera     0.0  0.0  \n",
       "bbc           1.0  0.0  \n",
       "breitbart     0.0  0.0  \n",
       "cnn           0.0  0.0  \n",
       "fox           0.0  3.0  \n",
       "\n",
       "[5 rows x 655 columns]"
      ]
     },
     "execution_count": 257,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Document_term_matrix #Viewing index added output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining Cosine function\n",
    "def cosine(a,b):\n",
    "    \"\"\"\n",
    "    The defined cosine function calculates the cosine value of the angle b/w the variables 'a','b' by using vector algebra concepts \n",
    "    of cos theta as dot product of (a,b) divided by magnitudes of 'a' &'b'\n",
    "    \n",
    "    \"\"\"\n",
    "    # using numpy package and  vector angle formula from math, define cos \n",
    "    cos = np.dot(a,b)/(np.sqrt(np.dot(a,a)) * np.sqrt(np.dot(b,b))) # \n",
    "    return cos #returns output of cosine function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creates an Correlation matrix to see the similarity of two articles by comparing their words\n",
    "def correl_matrix(df):\n",
    "    \"\"\"\n",
    "    The defined sm function produces a correlation matrix, by using cosine function defined earlier and numerical inputs \n",
    "    generated in Document_term_matrix and helps us identify the similarity of two vector variables. \n",
    "    \n",
    "    \"\"\"\n",
    "   \n",
    "    df_CM = pd.DataFrame(columns = df.index.values, index = df.index.values) #creating the dataframe\n",
    "    \n",
    "    for col in df_CM.columns:\n",
    "        for row in df_CM.index.values:\n",
    "            df_CM.loc[row, col] = cosine(df.loc[row].values, df.loc[col].values) #generating a dataframe of cosine values\n",
    "            \n",
    "    return(df_CM)# for printing output of the function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calling correl_matrix function for the output Document_term_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aljazeera</th>\n",
       "      <th>bbc</th>\n",
       "      <th>breitbart</th>\n",
       "      <th>cnn</th>\n",
       "      <th>fox</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>aljazeera</th>\n",
       "      <td>1</td>\n",
       "      <td>0.704952</td>\n",
       "      <td>0.588124</td>\n",
       "      <td>0.590484</td>\n",
       "      <td>0.709046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bbc</th>\n",
       "      <td>0.704952</td>\n",
       "      <td>1</td>\n",
       "      <td>0.588177</td>\n",
       "      <td>0.556742</td>\n",
       "      <td>0.662161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>breitbart</th>\n",
       "      <td>0.588124</td>\n",
       "      <td>0.588177</td>\n",
       "      <td>1</td>\n",
       "      <td>0.374829</td>\n",
       "      <td>0.54694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cnn</th>\n",
       "      <td>0.590484</td>\n",
       "      <td>0.556742</td>\n",
       "      <td>0.374829</td>\n",
       "      <td>1</td>\n",
       "      <td>0.558802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fox</th>\n",
       "      <td>0.709046</td>\n",
       "      <td>0.662161</td>\n",
       "      <td>0.54694</td>\n",
       "      <td>0.558802</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          aljazeera       bbc breitbart       cnn       fox\n",
       "aljazeera         1  0.704952  0.588124  0.590484  0.709046\n",
       "bbc        0.704952         1  0.588177  0.556742  0.662161\n",
       "breitbart  0.588124  0.588177         1  0.374829   0.54694\n",
       "cnn        0.590484  0.556742  0.374829         1  0.558802\n",
       "fox        0.709046  0.662161   0.54694  0.558802         1"
      ]
     },
     "execution_count": 262,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correl_matrix(Document_term_matrix) #printing output of correlation values/correlation matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Data Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scatter plot with square markers\n",
    "\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "corrplot(data.corr())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Output Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Aljazeera,BBC and Fox News texts were closely correlated(0.7).\n",
    "##### Breitbart and CNN have the lowest similarity values with each other(0.37). \n",
    "##### Also, Breitbart and CNN has a similar similarity levels with the other three texts(in the range of 0.5-0.6)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
