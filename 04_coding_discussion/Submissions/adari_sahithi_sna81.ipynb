{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Coding Discussion No. 4\n",
    "## Name: Sahithi Adari\n",
    "### Date: 11/01/20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Imported packages\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from string import punctuation\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Converted the csv file into a dataframe \n",
    "df_stopwords = pd.read_csv('stop_words.csv')\n",
    "\n",
    "#Coverted the dataframe into a list\n",
    "stopwords = df_stopwords['word'].values.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One note: I noticed when I was cleaning up the article text of punctuation marks, even if an article had quotation marks some of them were mapped differently than regular quotation marks. That is to say '“' was understood to be different than '\"' by the computer. We can show that difference by running the following functions: `ord('“')` and `ord('\"')`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8220"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ord('“')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "34"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ord('\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Created a function that will take a txt file and change it into a dataframe\n",
    "def txt_to_dtm(txt):\n",
    "    '''\n",
    "    Takes a txt file and returns it as a dataframe. The first part of the function also does some basic text clean up\n",
    "    by removing any punctuation found (using the 'string.punctuation' function), and removing any commonly found words\n",
    "    from the 'stopwords' csv. The second part of the function tracks how many times a specific word shows up in the\n",
    "    original txt file.\n",
    "\n",
    "    Args:\n",
    "        txt (txt file): a txt file of the article\n",
    "\n",
    "    Returns:\n",
    "        DataFrame: frame containing a tally of how often a unique word showed up in the article\n",
    "    '''\n",
    "    with open(txt) as file:\n",
    "        article = file.read().lower().replace('“', '').replace('”', '').replace('’','').split() #Removed any unique charecters\n",
    "        temp_article = [s.strip(punctuation) for s in article] #Removed any punctuation marks at the beginning and end of each word\n",
    "        clean_article = [word for word in temp_article if word not in stopwords] #Removed any commonly used words\n",
    "    d = dict()\n",
    "    for letter in clean_article: #Counted how often a specific word shows up in the txt file\n",
    "        if letter in d:\n",
    "            d[letter][0] += 1\n",
    "        else:\n",
    "            d[letter] = [1]\n",
    "    return pd.DataFrame(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Created a function that coverts multiple txt articles in dataframes\n",
    "def gen_DTM(*texts):\n",
    "    '''\n",
    "    Takes multiple txt files and returns it as a dataframe by passing through the 'txt_to_dtm' function and then appending\n",
    "    the individual dataframe to an overall dataframe called 'DTM'.\n",
    "\n",
    "    Args:\n",
    "        *texts (txt files): multiple txt files\n",
    "\n",
    "    Returns:\n",
    "        DTM: a dataframe appeneded with all the individual dataframes generated from 'txt_to_dtm'\n",
    "    '''\n",
    "    DTM = pd.DataFrame()\n",
    "    for a in texts:\n",
    "        entry = txt_to_dtm(a) #Passed each article into the 'txt_to_dtm' function\n",
    "        DTM = DTM.append(entry, ignore_index = True) #Appeneded the dataframe from 'txt_to_dtm' to 'DTM'\n",
    "    DTM.fillna(0, inplace=True) #Filled in any missing values with 0s (i.e. when a word is in one text but not another)\n",
    "    return DTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Created a function that easily calculates the angle between two vectors\n",
    "def cosine(a,b):\n",
    "    '''\n",
    "    A function that easily calculates the angle between two vectors.\n",
    "    Args:\n",
    "        a,b : two vectors of the same length\n",
    "\n",
    "    Returns:\n",
    "        cos: the angle between the two vectors\n",
    "    '''\n",
    "    cos = np.dot(a,b)/(np.sqrt(np.dot(a,a)) * np.sqrt(np.dot(b,b)))\n",
    "    return cos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Created a function that calcuate the similarity between a combination of different\n",
    "def article_similar(*docs):\n",
    "    '''\n",
    "    Takes multiple txt files and calculates the similarity between the texts by passing the articles through the\n",
    "    'txt_to_dtm', 'gen_DTM' functions first and then calcuates the cosine. This funtion also goes through all\n",
    "    possible combinations of articles.\n",
    "\n",
    "    Args:\n",
    "        *docs (txt files): multiple txt files\n",
    "\n",
    "    Returns:\n",
    "        A printed label of what articles are being compared and the respective similarity between the two articles\n",
    "    '''\n",
    "    D = gen_DTM(*docs) #Passed *docs through 'gen_DTM' and set that equal to D\n",
    "    for i in range(5):\n",
    "        for j in range(i+1,5):\n",
    "            print(\"Cosine similarity between\", docs[i], \"and\", docs[j], \"is\",\n",
    "                  round((cosine(D.iloc[i].values, D.iloc[j].values)), 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cosine similarity between bbc-khashoggi.txt and aljazeera-khashoggi.txt is 0.6951\n",
      "Cosine similarity between bbc-khashoggi.txt and breitbart-khashoggi.txt is 0.5813\n",
      "Cosine similarity between bbc-khashoggi.txt and cnn-khashoggi.txt is 0.5205\n",
      "Cosine similarity between bbc-khashoggi.txt and fox-khashoggi.txt is 0.6506\n",
      "Cosine similarity between aljazeera-khashoggi.txt and breitbart-khashoggi.txt is 0.5825\n",
      "Cosine similarity between aljazeera-khashoggi.txt and cnn-khashoggi.txt is 0.5329\n",
      "Cosine similarity between aljazeera-khashoggi.txt and fox-khashoggi.txt is 0.6778\n",
      "Cosine similarity between breitbart-khashoggi.txt and cnn-khashoggi.txt is 0.3664\n",
      "Cosine similarity between breitbart-khashoggi.txt and fox-khashoggi.txt is 0.547\n",
      "Cosine similarity between cnn-khashoggi.txt and fox-khashoggi.txt is 0.5153\n"
     ]
    }
   ],
   "source": [
    "article_similar('bbc-khashoggi.txt', 'aljazeera-khashoggi.txt', 'breitbart-khashoggi.txt', 'cnn-khashoggi.txt', 'fox-khashoggi.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Use what we know about (a) reading in text files, (b) data manipulation, and (c) linear algebra to analyze the difference between these documents. Does each news site report on these stories in a similar way? Which news sites talk about the Khashoggi scandal in similar/dissimilar ways? If you change what words you remove, does the picture of similarity change?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As the *article_similar* function shows, the 5 different news sources moderately report on the Khashoggi scandal in the same way. The greatest similarity was found between Al Jazeera & BBC coming in at $0.6951$; with Al Jazeera & Fox at $0.6778$ ; and BBC & Fox at $0.6506$ if we remove all common words and punctuations from the text. The news organizations that were the most dissimilar were Breitbart & CNN at $0.3664$.\n",
    "\n",
    "But what happens if we leave the common words in the articles instead of removing them? We can do this simply by commenting out a line of code (which I’ve reproduced down below), and making slight tweaks to that same function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Same function as above but with commented out code to not remove common words\n",
    "def txt_to_dtm(txt):\n",
    "    with open(txt) as file:\n",
    "        article = file.read().lower().replace('“', '').replace('”', '').replace('’','').split()\n",
    "        temp_article = [s.strip(punctuation) for s in article]\n",
    "        #clean_article = [word for word in temp_article if word not in stopwords] \n",
    "    d = dict()\n",
    "    for letter in temp_article: #Changed 'clean_article' to 'temp_article' here\n",
    "        if letter in d:\n",
    "            d[letter][0] += 1\n",
    "        else:\n",
    "            d[letter] = [1]\n",
    "    return pd.DataFrame(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "article_similar('bbc-khashoggi.txt', 'aljazeera-khashoggi.txt', 'breitbart-khashoggi.txt', 'cnn-khashoggi.txt', 'fox-khashoggi.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we include common words back into the measurement of similarity we can see that similarity between all 5 news organizations shot up. Most notably, Breitbart & CNN shot up to $0.6793$. This makes sense as the cosine function is simply calculating the \"difference of angles\" between 2 vectors. The vectors here represent the frequency by which certain words show up; once we include common words back into the measurement, it's only natural that the measurement of similarity would increase.\n",
    "\n",
    "What happens when we exclude the stripping of punctuation (save for the unique characters) from the texts?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Same function as the original but with commented out code to not remove punctuation\n",
    "def txt_to_dtm(txt):\n",
    "    with open(txt) as file:\n",
    "        article = file.read().lower().replace('“', '').replace('”', '').replace('’','').split()\n",
    "        #temp_article = [s.strip(punctuation) for s in article]\n",
    "        clean_article = [word for word in article if word not in stopwords] #Changed 'temp_article' to 'article' here\n",
    "    d = dict()\n",
    "    for letter in clean_article:\n",
    "        if letter in d:\n",
    "            d[letter][0] += 1\n",
    "        else:\n",
    "            d[letter] = [1]\n",
    "    return pd.DataFrame(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "article_similar('bbc-khashoggi.txt', 'aljazeera-khashoggi.txt', 'breitbart-khashoggi.txt', 'cnn-khashoggi.txt', 'fox-khashoggi.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once we leave punctuation in the articles sink back down to original levels. This goes to show that while removing punctuation helps generate a closer estimate in terms of similarity it doesn’t have to be necessary.\n",
    "\n",
    "Lastly, what happens if we add \"turkey\", \"khashoggi\" and \"erdogan\" to our common words list? We can do that by adding those 3 values to *df_stopwords* and resaving it as a new dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Converted the csv file into a dataframe\n",
    "stopwords_turkey = df_stopwords.append({'word': 'turkey', 'word': 'khashoggi', 'word': 'erdogan'}, ignore_index = True)\n",
    "\n",
    "#Coverted the dataframe into a list\n",
    "stopwords = stopwords_turkey['word'].values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The original function\n",
    "def txt_to_dtm(txt):\n",
    "    with open(txt) as file:\n",
    "        article = file.read().lower().replace('“', '').replace('”', '').replace('’','').split()\n",
    "        temp_article = [s.strip(punctuation) for s in article]\n",
    "        clean_article = [word for word in temp_article if word not in stopwords]\n",
    "    d = dict()\n",
    "    for letter in clean_article:\n",
    "        if letter in d:\n",
    "            d[letter][0] += 1\n",
    "        else:\n",
    "            d[letter] = [1]\n",
    "    return pd.DataFrame(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cosine similarity between bbc-khashoggi.txt and aljazeera-khashoggi.txt is 0.6755\n",
      "Cosine similarity between bbc-khashoggi.txt and breitbart-khashoggi.txt is 0.5639\n",
      "Cosine similarity between bbc-khashoggi.txt and cnn-khashoggi.txt is 0.4843\n",
      "Cosine similarity between bbc-khashoggi.txt and fox-khashoggi.txt is 0.6331\n",
      "Cosine similarity between aljazeera-khashoggi.txt and breitbart-khashoggi.txt is 0.564\n",
      "Cosine similarity between aljazeera-khashoggi.txt and cnn-khashoggi.txt is 0.4666\n",
      "Cosine similarity between aljazeera-khashoggi.txt and fox-khashoggi.txt is 0.6133\n",
      "Cosine similarity between breitbart-khashoggi.txt and cnn-khashoggi.txt is 0.3296\n",
      "Cosine similarity between breitbart-khashoggi.txt and fox-khashoggi.txt is 0.532\n",
      "Cosine similarity between cnn-khashoggi.txt and fox-khashoggi.txt is 0.4297\n"
     ]
    }
   ],
   "source": [
    "article_similar('bbc-khashoggi.txt', 'aljazeera-khashoggi.txt', 'breitbart-khashoggi.txt', 'cnn-khashoggi.txt', 'fox-khashoggi.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Even if we add those 3 values to the common words list there doesn't seem to be that big of a difference between the 5 news organization.\n",
    "\n",
    "The \"biggest\" difference we do see is between Al Jazeera & CNN and CNN & Fox. Where as before (removing punctuation and commons words pre-addition of the three above) the similarity between Al Jazeera & Fox was at $0.5329$, that value drops to $0.4666$. For CNN & Fox this value goes from $0.5153$ to $0.4297$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
